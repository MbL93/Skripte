{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_tut_6_homework_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaF5tBX1OqJQ",
        "colab_type": "text"
      },
      "source": [
        "## Exercise - DL Tutorial 6 \n",
        "\n",
        "Please complete the following notebook and submit your solutions to thomas.wiest@informatik.uni-augsburg.de and manuel.milling@informatik.uni-augsburg.de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ot2wY0OMosh",
        "colab_type": "text"
      },
      "source": [
        "# Student name:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMoFYSyJLXl8",
        "colab_type": "text"
      },
      "source": [
        "For training the models of this exercise you should split your data into a train, validation and a test partition. The test set is usually given by loading the dataset using the Keras API. You should split the training set into a train and a validation partition either by hand or by using methods provided by Keras. You should adjust your network by using the train and validation set and do the final evaluation on the test set. For both datasets used in this tutorial the validation and the test set should contain about 10\\,000 samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efx7CsjfK5-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "c0f11ab8-71ce-4a3a-cd9b-d59c7735340c"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DnFtZFtN-_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPJ8UUXcLRz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "50639276-e375-465d-e79d-ef8e1ec3f597"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_test = x_test.astype(np.float32) / 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI45SirTL0c2",
        "colab_type": "text"
      },
      "source": [
        "Exercise 2 - MNIST Classification using Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYjbEAkL0tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGml437mL9--",
        "colab_type": "text"
      },
      "source": [
        "Exercise 3 - MNIST Classification using Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suN0aCc1L-SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsNi20eZMzeD",
        "colab_type": "text"
      },
      "source": [
        "Exercise 4 - Parameter Count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C73CcBG_M5zl",
        "colab_type": "text"
      },
      "source": [
        "Exercise 5 - Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rv9x0yJM7eb",
        "colab_type": "text"
      },
      "source": [
        "Exercise 6 - Max Pooling and Strided Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwcDBweCM_zt",
        "colab_type": "text"
      },
      "source": [
        "Optional: CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaWMIvvwLoc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "34ed764f-f06d-46c6-8999-2f6e1fe9eecf"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_test = x_test.astype(np.float32) / 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpXtOBWzPS_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}